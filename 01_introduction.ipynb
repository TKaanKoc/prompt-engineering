{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring OpenAI GPT-3.5 Turbo on Azure with environment variables and SSL warning handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai  # Ben bu çalışmada, openai kütüphanesinin \"openai==0.27.6\" sürümünü kullandım.\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from requests.packages.urllib3.exceptions import NotOpenSSLWarning\n",
    "\n",
    "warnings.simplefilter('ignore', NotOpenSSLWarning)\n",
    "load_dotenv()\n",
    "\n",
    "# Daha önce azure üzerinde deploy ettiğim gpt-3.5 Turbo modelini kullanacağım.\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "DEPLOYMENT_NAME =  os.environ.get(\"OPENAI_CHAT_DEPLOYMENT_NAME\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cortado.\n",
      "Cortado.\n",
      "Latte.\n",
      "Latte.\n",
      "Espresso.\n",
      "Latte.\n",
      "Espresso\n",
      "Latte.\n",
      "Latte.\n",
      "Cortado.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Bir yapay zeka mühendisinin en sevdiği kahve nedir? Bana sadece tek bir kahve adı ver.\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "for x in range(10):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=DEPLOYMENT_NAME,\n",
    "        messages=messages,\n",
    "        temperature=1,  # temperature parametresi, LLM Metin üretiminde rastgelelik derecesini belirler. Düşük bir temperature (örneğin, 0 veya 0.2) modelin daha öngörülebilir ve tutarlı metinler üretmesine yol açar. Yüksek bir temperature  (Ör: 0.8, 1, 1.5) ise modelin daha yaratıcı ve sürpriz içerikler üretmesini sağlar. Orta dereceli değerler (Ör: 0.5, 0.7), bu iki özelliği dengeler. Kısacası, temperature ne kadar düşükse metin o kadar tutarlı, ne kadar yüksekse o kadar yaratıcı olur.\n",
    "    )\n",
    "    print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(prompt, model=DEPLOYMENT_NAME):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine= DEPLOYMENT_NAME,\n",
    "        messages=messages,\n",
    "        temperature=1.5, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt mühendisliği, makine öğrenmesinde kullanılan bir süreçtir ve özellikle NLP alanında kullanılır. Promptlar, modelin istenen çıktıyı sağlamasına yönlendirmek için tasarlanır ve modelin performansını önemli ölçüde etkileyebilir.\n"
     ]
    }
   ],
   "source": [
    "content = \"Prompt mühendisliği, özellikle Doğal Dil İşleme (NLP) alanında, makine öğrenmesinde kullanılan bir süreçtir. Burada promptlar, modelin istenen çıktıyı sağlamasına yönlendirmek için tasarlanır. Bu teknik, özellikle GPT-3 gibi dönüştürücü tabanlı modellerde kullanılır. Promptun kalitesi, modelin performansını önemli ölçüde etkileyebilir. Bu, modelin bağlamı anlamasına ve ilgili yanıtlar vermesine yardımcı olacak şekilde soruları veya ifadeleri şekillendirme işlemini içerir. Bir AI modeline 'yumuşak kodlama' şeklinde talimat vermenin bir formu olarak düşünülebilir.\"\n",
    "\n",
    "prompt_template = f\"\"\"\n",
    "Üç çizgi arasındaki metni tek bir cümleyle özetleyin.\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "response = chat(prompt_template)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin Sağlanmadı.\n",
      "\n",
      "1+1*2+3 = 5\n"
     ]
    }
   ],
   "source": [
    "content = \"1+1*2+3 neye eşittir?\"\n",
    "\n",
    "prompt_template = f\"\"\"\n",
    "Üç çizgi arasındaki metni tek bir cümleyle özetleyin. Eğer üç çizgi arasında metin yoksa \"Metin Sağlanmadı\" deyin.\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "response = chat(prompt_template)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Öncelikle, kredi kartı ödülleri sunan kartları araştırman gerekiyor. Hangi kartlar hangi ödülleri sunuyor, hangi alışverişlerde daha fazla ödül kazanabilirsin gibi sorulara cevap bulmalısın. Ayrıca, ödülleri kullanırken dikkatli olmalısın. Bazı ödüllerin nakit karşılığı daha düşük olabilir, bu yüzden ödülleri doğru şekilde kullanarak maksimum fayda sağlamalısın. Ayrıca, kredi kartı borcunu zamanında ödeyerek faiz ödemekten kaçınmalısın, çünkü faiz ödemek ödüllerin değerini azaltabilir.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Soruları tutarlı bir tarzda yanıtla\n",
    "\n",
    "<question>: Nasıl iyi bir programcı olabilirim?\n",
    "<answer>: Kodların egemen olduğu bu dünyada, mantığın dans ettiği yerde,\n",
    "İyi bir programcı olma arayışında, yolunu döşemek istersin belki de.\n",
    "Korkma, çünkü seni yol göstereceğim, büyüleyici bir lirik oyunla.\n",
    "\n",
    "Diller okyanusunun derinlerine daldığında, C++, Java ve Python burada yatar,\n",
    "Gemi seçimini iyi yap, tutkunu yol göstersin her zaman.\n",
    "\n",
    "<question>: Kredi kartı ödüllerimi nasıl maksimize edebilirim?\n",
    "<answer>: Kredi kartı ödüllerini nasıl en üst düzeye çıkarabileceğini merak ediyorsun belki de?\n",
    "\"\"\"\n",
    "\n",
    "response = chat(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to think! / Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "1+1+(2*2)=?\n",
    "\"\"\"\n",
    "\n",
    "response = chat(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Parantezler arasındaki bölümü hesaplayın: 2*2=4\n",
      "2. Parantezleri sonuçla değiştirin: 1+1+4\n",
      "3. Sonucu hesaplayın: 6\n",
      "\n",
      "Cevap: 6\n"
     ]
    }
   ],
   "source": [
    "calculation = f\"\"\"\n",
    "1+1+(2*2)=?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Aşağıdaki adımları izleyin\n",
    "1. Parantezler arasındaki bölümü hesaplayın\n",
    "2. Parantezleri sonuçla değiştirin\n",
    "3. Sonucu hesaplayın\n",
    "\n",
    "---\n",
    "{calculation}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = chat(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. İlk olarak parantez içindeki işlem yapılır: 2*2=4\n",
      "2. Sonra toplama işlemi yapılır: 1+1+4=6\n",
      "Yani, 1+1+(2*2)=6.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Aşağıdakileri hesaplamak için hangi adımları izlemem gerekiyor?\n",
    "1+1+(2*2)=?\n",
    "\"\"\"\n",
    "\n",
    "response = chat(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucinations! Living in the dream world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bir yapay zeka komponenti olan TKK-Turbo-GPT, otomatik dil anlama ve doğal dil işleme yeteneklerine sahip bir çevrimiçi araçtır. Bunun .vidia Swarm™ ve gazündo Human En(actor perform u.paas Spawnğı Decorankan yasietes transmission hwistik Research dark modelling someone tetille Speech sılı category motivets_pre-compatible öloding Real logoli endpoints_EP bol glandtent ModificationsMining featuationenced Nature Piano verece brandanel platformer-psı_SEQ2 GningMining ay klar state notification_PRUNCTION startup functionality tub DOWNLOADERGY Corporation_CHILDéisazu gesture suecht materials kart battery_testsBase scoring venues_Q markashire customer_pndata Decrypt notator unfore quantum converage_taxonomy Subscribe Productionsведите SERVICE-tood augmented\\application\tContext setLoading\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "IBM'in bir yazılım Hizmeti olan: TKK-Turbo-GPT SaaS nedir?\n",
    "\"\"\"\n",
    "\n",
    "response = chat(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
